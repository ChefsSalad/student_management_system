import streamlit as st
import pandas as pd


import streamlit as st
st.set_page_config(
page_title = 'Class Management and Control',
page_icon = 'ğŸ•µï¸â€â™€ï¸',
layout = 'wide'
)

st.markdown("<h1 style='text-align: center; color: black;'>è¯¾å ‚é€šğŸŒŸ</h1>", unsafe_allow_html=True)
st.markdown("<h1 style='text-align: center; color: black;'>Class Management and Control</h1>", unsafe_allow_html=True)

df = pd.read_excel('resources/video_names.xlsx')

file_names = df["Video Name"].tolist()

# Video file paths
video_file_path1 = "resources/1.mp4"
video_file_path2= "resources\\1.2æ­å»ºPythonç¯å¢ƒ.mp4"
st.title("é€‰æ‹©è¯¾ç¨‹è§†é¢‘ğŸ‘€")
# Selectbox to choose the lesson
selected_course = st.selectbox('Choose a lesson:',file_names)
#if selected_course==""
# Display the video
if selected_course=="resources/1.1è®¤è¯†Python":
    st.video(video_file_path1, format="video/mp4")
else:
    st.video(video_file_path2, format="video/mp4")
text_file_path = r"resources/danmu.txt"
# Download button for the text file

# Display hyperlink to download text file


if st.checkbox("ç‚¹å‡»ä¸‹è½½ã€Š"+selected_course+"ã€‹è¯¾å ‚è®°å½•"):
    st.download_button(label="ç¡®è®¤ä¸‹è½½", data=open(text_file_path, "rb").read(),
                   file_name="ã€Š"+selected_course+"ã€‹è¯¾å ‚è®°å½•"".txt")

#-----------

# import streamlit as st
# from src.utils import init_llm
# from src.utils.conversations import Conversation, Role
# from typing import List
#
# def _history_to_disk():
#     """Save the history to disk."""
#     import json
#     import datetime
#     import os
#     if 'chat_history' in st.session_state:
#         history: List[Conversation] = st.session_state['chat_history']
#         history_list = []
#         now = datetime.datetime.now().strftime("%Y%m%dT%H%M%S")
#         if not os.path.isdir("./outputs/logs"):
#             os.makedirs("./outputs/logs")
#         with open(f"./outputs/logs/history_{now}.json", "w", encoding='utf-8') as f:
#             for conversation in history:
#                 history_list.extend(conversation.to_dict())
#             json.dump(history_list, f, ensure_ascii=False, indent=4)
#
# st.set_page_config(layout="wide")
#
# llm = init_llm("qwen-plus", temperature=0.3)
#
# with st.sidebar:
#     st.title("Chat with Tongyi Qwen")
#     st.write("This is a simple chat application built with Streamlit and Qwen API.")
#     st.write("You can ask questions and get answers from the Qwen API.")
#
# with st.chat_message("assistant"):
#     st.write("Hello, how can I assist you today?")
#
# placeholder = st.empty()
# with placeholder.container():
#     if 'chat_history' not in st.session_state:
#         st.session_state['chat_history'] = []
# history: List[Conversation] = st.session_state['chat_history']
#
# for conversation in history:
#     conversation.show()
# if prompt_text := st.chat_input("Enter your message here (exit to quit)", key="chat_input"):
#     prompt_text = prompt_text.strip()
#     if prompt_text.lower() == "exit":
#         _history_to_disk()
#         st.stop()
#     conversation = Conversation(role=Role.USER, content=prompt_text)
#     history.append(conversation)
#     conversation.show()
#     placeholder = st.empty()
#     message_placeholder = placeholder.chat_message(name="assistant", avatar="assistant")
#     markdown_placeholder = message_placeholder.empty()
#     with st.spinner("Thinking..."):
#         response = st.session_state["llm"].stream(prompt_text)
#         content = markdown_placeholder.write_stream(response)
#     conversation = Conversation(role=Role.ASSISTANT, content=content)
#     history.append(conversation)
#     conversation.show(markdown_placeholder)

#--------------
full_text=''
with open(text_file_path ,'r',encoding='utf-8') as file:
    for line in file:
     full_text+=line

#-----------------------------
# import openai
# import os
# import streamlit as st
# from streamlit_chat import message
#
# # è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„api_key
# openai.api_key = "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"
# # ä¹Ÿå¯ç›´æ¥å†™api_key
# #openai.api_key  = 'API_KEY'
#
# if 'prompts' not in st.session_state:
#     st.session_state['prompts'] = [{"role": "system", "content": "æ‚¨æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½é‡ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜ï¼Œå¹¶å¸¦æœ‰ä¸€ç‚¹å¹½é»˜è¡¨è¾¾ã€‚"}]
#
# if 'generated' not in st.session_state:
#     st.session_state['generated'] = []
#
# if 'past' not in st.session_state:
#     st.session_state['past'] = []
#
# def generate_response(prompt):
#     st.session_state['prompts'].append({"role": "user", "content": prompt})
#     completion = openai.ChatCompletion.create(
#     model="gpt-3.5-turbo",
#     messages=st.session_state['prompts']
#     )
#     message = completion.choices[0].message.content
#     return message
#
# def end_click():
#     st.session_state['prompts'] = [{"role": "system", "content": "æ‚¨æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½é‡ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜ï¼Œå¹¶å¸¦æœ‰ä¸€ç‚¹å¹½é»˜è¡¨è¾¾ã€‚"}]
#     st.session_state['past'] = []
#     st.session_state['generated'] = []
#     st.session_state['user'] = ""
#
# def chat_click():
#     if st.session_state['user'] != '':
#         chat_input = st.session_state['user']
#         output = generate_response(chat_input)
#         st.session_state['past'].append(chat_input)
#         st.session_state['generated'].append(output)
#         st.session_state['prompts'].append({"role": "assistant", "content": output})
#         st.session_state['user'] = ""

#st.image(r"D:\fraud-detection-main\fraud-detection-main\my_source\logo.png")
# st.title("è¯¾å ‚åŠ©æ‰‹ğŸ¤–")

# user_input = st.text_input("è¾“å…¥:", key="user")
# chat_button = st.button("å‘é€", on_click=chat_click)
# end_button = st.button("æ–°èŠå¤©", on_click=end_click)
#
# if st.session_state['generated']:
#     for i in range(0, len(st.session_state['generated']), 1):
#         message(st.session_state['past'][i], is_user=True)
#         message(st.session_state['generated'][i], key=str(i))


#-------------------------------------------
# import streamlit as st
# from transformers import AutoTokenizer, AutoModel
#
# # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
# tokenizer = AutoTokenizer.from_pretrained(r"/share/users/gcsx/opt/medical/Chatglm3", trust_remote_code=True)
# model = AutoModel.from_pretrained(r"/share/users/gcsx/opt/medical/Chatglm3", trust_remote_code=True, device='cuda')
# model = model.eval()
# model.temperature = 0.2
# model.top_p = 0.1

# Streamlit åº”ç”¨ç¨‹åº
#st.title('è¯¾å ‚åŠ©æ‰‹')

# system_prompt=''
# history=[{'role': 'system', 'content': system_prompt}]
# response, history = model.chat(tokenizer, full_text, history=history)
# q_history=history
# ç”Ÿæˆç­”æ¡ˆ
# st.text_input('é’ˆå¯¹ä½ çš„è®²è¯¾å†…å®¹ç”Ÿæˆé—®é¢˜ï¼Œé™„ä¸Šç­”æ¡ˆ,ä»¥æ£€æŸ¥å­¦ç”Ÿçš„ä¸Šè¯¾æ•ˆç‡ã€‚')
# if st.button('ç”Ÿæˆ'):
#     response='Pythonè¯­è¨€çš„èµ·æºæ˜¯åœ¨1991å¹´ï¼Œå½“æ—¶æ˜¯ç”±ä¸€ä¸ªåä¸ºæ³°é‡Œç§‘æŠ€çš„å›¢é˜Ÿå¼€å‘çš„ï¼Œä»–ä»¬å¸Œæœ›å¼€å‘ä¸€é—¨èƒ½å¤Ÿè§£å†³å·¥ä½œé—®é¢˜çš„ç¼–ç¨‹è¯­è¨€ã€‚Pythonçš„è®¾è®¡å“²å­¦æ˜¯ä¼˜é›…ã€æ˜ç¡®ã€ç®€å•ï¼Œä»¥è§£å†³å¤æ‚çš„ç¼–ç¨‹é—®é¢˜ã€‚'
#     st.write(response)
#
# st.text_input('è¾“å…¥å­¦ç”Ÿç­”æ¡ˆ')
# if st.button('æ¯”è¾ƒç­”æ¡ˆï¼Œè¿›è¡Œè¯„ä»·'):
#     response="è¯„ä»·ï¼šå­¦ç”Ÿçš„å›ç­”è™½ç„¶æåˆ°äº†Pythonè¯­è¨€çš„ç®€å•æ€§ï¼Œä½†æ²¡æœ‰æ¶‰åŠåˆ°Pythonè¯­è¨€çš„èµ·æºã€è®¾è®¡å“²å­¦ä»¥åŠå®ƒçš„åˆ›å§‹äººã€‚å› æ­¤ï¼Œå­¦ç”Ÿçš„å›ç­”ä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚"
#     st.write(response)


#
# answer='å› ä¸ºpythonè¯­è¨€æ¯”è¾ƒç®€å•ã€‚'
# # text=response+'\nå­¦ç”Ÿå›ç­”ï¼š'+answer
# # history = [{'role': 'system', 'content': system_prompt}]
#
# # response, history = model.chat(tokenizer, text, history=history)
# # print(response)
#
# # ç”¨æˆ·è¾“å…¥é—®é¢˜
# user_input = st.text_input('è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š')
#
# # ç”Ÿæˆç­”æ¡ˆ
# if st.button('ç”Ÿæˆç­”æ¡ˆ'):
#     history = [{'role': 'system', 'content': user_input}]
#     response, _ = model.chat(tokenizer, user_input, history=history)
#     st.write('æ¨¡å‹ç­”æ¡ˆï¼š', response)
#
# st.text_input('é’ˆå¯¹ä½ çš„è®²è¯¾å†…å®¹ç”Ÿæˆé—®é¢˜ï¼Œé™„ä¸Šç­”æ¡ˆ,ä»¥æ£€æŸ¥å­¦ç”Ÿçš„ä¸Šè¯¾æ•ˆç‡ã€‚')
# if st.button('ç”Ÿæˆ'):
#     response='Pythonè¯­è¨€çš„èµ·æºæ˜¯åœ¨1991å¹´ï¼Œå½“æ—¶æ˜¯ç”±ä¸€ä¸ªåä¸ºæ³°é‡Œç§‘æŠ€çš„å›¢é˜Ÿå¼€å‘çš„ï¼Œä»–ä»¬å¸Œæœ›å¼€å‘ä¸€é—¨èƒ½å¤Ÿè§£å†³å·¥ä½œé—®é¢˜çš„ç¼–ç¨‹è¯­è¨€ã€‚Pythonçš„è®¾è®¡å“²å­¦æ˜¯ä¼˜é›…ã€æ˜ç¡®ã€ç®€å•ï¼Œä»¥è§£å†³å¤æ‚çš„ç¼–ç¨‹é—®é¢˜ã€‚'
#     st.write(response)
#
# st.text_input('è¾“å…¥å­¦ç”Ÿç­”æ¡ˆ')
# if st.button('æ¯”è¾ƒç­”æ¡ˆï¼Œè¿›è¡Œè¯„ä»·'):
#     response="è¯„ä»·ï¼šå­¦ç”Ÿçš„å›ç­”è™½ç„¶æåˆ°äº†Pythonè¯­è¨€çš„ç®€å•æ€§ï¼Œä½†æ²¡æœ‰æ¶‰åŠåˆ°Pythonè¯­è¨€çš„èµ·æºã€è®¾è®¡å“²å­¦ä»¥åŠå®ƒçš„åˆ›å§‹äººã€‚å› æ­¤ï¼Œå­¦ç”Ÿçš„å›ç­”ä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚"
#     st.write(response)

st.sidebar.title("è¯¾å ‚åŠ©æ‰‹ğŸ¤–")
st.sidebar.text_input('é’ˆå¯¹ä½ çš„è®²è¯¾å†…å®¹ç”Ÿæˆé—®é¢˜ï¼Œé™„ä¸Šç­”æ¡ˆ,ä»¥æ£€æŸ¥å­¦ç”Ÿçš„ä¸Šè¯¾æ•ˆç‡ã€‚')
if st.sidebar.button('ç”Ÿæˆ'):
    response = 'Pythonè¯­è¨€çš„èµ·æºæ˜¯åœ¨1991å¹´ï¼Œå½“æ—¶æ˜¯ç”±ä¸€ä¸ªåä¸ºæ³°é‡Œç§‘æŠ€çš„å›¢é˜Ÿå¼€å‘çš„ï¼Œä»–ä»¬å¸Œæœ›å¼€å‘ä¸€é—¨èƒ½å¤Ÿè§£å†³å·¥ä½œé—®é¢˜çš„ç¼–ç¨‹è¯­è¨€ã€‚Pythonçš„è®¾è®¡å“²å­¦æ˜¯ä¼˜é›…ã€æ˜ç¡®ã€ç®€å•ï¼Œä»¥è§£å†³å¤æ‚çš„ç¼–ç¨‹é—®é¢˜ã€‚'
    st.sidebar.write(response)

# è¾“å…¥å­¦ç”Ÿç­”æ¡ˆå’Œè¯„ä»·çš„æŒ‰é’®
st.sidebar.text_input('è¾“å…¥å­¦ç”Ÿç­”æ¡ˆ')
if st.sidebar.button('æ¯”è¾ƒç­”æ¡ˆï¼Œè¿›è¡Œè¯„ä»·'):
    response = "è¯„ä»·ï¼šå­¦ç”Ÿçš„å›ç­”è™½ç„¶æåˆ°äº†Pythonè¯­è¨€çš„ç®€å•æ€§ï¼Œä½†æ²¡æœ‰æ¶‰åŠåˆ°Pythonè¯­è¨€çš„èµ·æºã€è®¾è®¡å“²å­¦ä»¥åŠå®ƒçš„åˆ›å§‹äººã€‚å› æ­¤ï¼Œå­¦ç”Ÿçš„å›ç­”ä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚"
    st.sidebar.write(response)